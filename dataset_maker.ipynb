{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "from math import comb\n",
    "import random\n",
    "import shutil\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a3574",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6460a57",
   "metadata": {},
   "source": [
    "**Dataset Preparation Overview**\n",
    "\n",
    "This notebook focuses on preparing a dataset of fluid flow images by:\n",
    "\n",
    "- Loading and binarizing input images\n",
    "\n",
    "- Performing interpolation between images to generate intermediate frames\n",
    "\n",
    "- Processing and saving the resulting dataset\n",
    "\n",
    "- Analyzing image dimensions across the dataset\n",
    "\n",
    "**Key steps include:**\n",
    "\n",
    "- Contour-based interpolation between pairs of images\n",
    "\n",
    "- Weighted blending of image features\n",
    "\n",
    "- Padding images to consistent dimensions\n",
    "\n",
    "- Generating meaningful filenames for blended images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b365135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_binarize(image_path):\n",
    "    \"\"\"Loads an image from given path and converts it to binary format using thresholding.\n",
    "    Args:\n",
    "        image_path (str): Path to the input image file\n",
    "    Returns:\n",
    "        numpy.ndarray: Binarized image array\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    return np.array(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_max(col):\n",
    "    \"\"\"Finds the minimum and maximum y-indices where pixel values are 0 (black) in a column.\n",
    "    Args:\n",
    "        col (numpy.ndarray): Single column of image data\n",
    "    Returns:\n",
    "        tuple: (y_min, y_max) coordinates of first and last black pixels\n",
    "    \"\"\"\n",
    "    zero_indices = np.argwhere(col == 0)\n",
    "    \n",
    "    y_min = int(np.min(zero_indices))\n",
    "    y_max = int(np.max(zero_indices))\n",
    "    \n",
    "    return y_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f9317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def both_have_points(col1,col2):\n",
    "    \"\"\"Checks if both columns contain at least one black pixel (value 0).\n",
    "    Args:\n",
    "        col1 (numpy.ndarray): First image column\n",
    "        col2 (numpy.ndarray): Second image column\n",
    "    Returns:\n",
    "        bool: True if both columns contain black pixels\n",
    "    \"\"\"\n",
    "    col1_have = len(np.argwhere(col1 == 0)) > 0\n",
    "    col2_have = len(np.argwhere(col2 == 0)) > 0\n",
    "    return col1_have & col2_have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46451d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted(col1, col2, weight=0.5):\n",
    "    \"\"\"Calculates weighted average of min/max positions between two columns.\n",
    "    Args:\n",
    "        col1 (numpy.ndarray): First image column\n",
    "        col2 (numpy.ndarray): Second image column\n",
    "        weight (float): Blend weight between 0-1\n",
    "    Returns:\n",
    "        tuple: (y_w_min, y_w_max) weighted positions\n",
    "    \"\"\"\n",
    "    y1_min, y1_max = find_min_max(col1)\n",
    "    y2_min, y2_max = find_min_max(col2)\n",
    "    y_w_min = int((1-weight)*y1_min + weight*y2_min)\n",
    "    y_w_max = int((1-weight)*y1_max + weight*y2_max)\n",
    "    \n",
    "    return y_w_min, y_w_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271854ef",
   "metadata": {},
   "source": [
    "Interpolation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eeb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(img1,img2,n_step=1):\n",
    "    \"\"\"Generates interpolated images between two input images using contour blending.\n",
    "    Args:\n",
    "        img1 (numpy.ndarray): First input image\n",
    "        img2 (numpy.ndarray): Second input image\n",
    "        n_step (int): Number of interpolation steps\n",
    "    Returns:\n",
    "        list: List of interpolated images\n",
    "        list: List of corresponding weights\n",
    "    \"\"\"\n",
    "    \n",
    "    H1, W1 = img1.shape\n",
    "    H2, W2 = img2.shape\n",
    "    H = max(H1,H2)\n",
    "    W = min(W1,W2)\n",
    "\n",
    "    weight_step = 1 / (n_step+1)\n",
    "    weights = [weight_step*i for i in range(n_step+1)]\n",
    "    weights = weights[1:]\n",
    "\n",
    "    img_list = []\n",
    "    for weight in weights:\n",
    "        \n",
    "        img_w = 255*np.ones((H,W))\n",
    "        for i in range(W):\n",
    "            if both_have_points(img1[:,i],img2[:,i]):\n",
    "            \n",
    "                y_w_min, y_w_max = calculate_weighted(img1[:,i],img2[:,i],weight=weight)\n",
    "                img_w[y_w_min:y_w_max+1,i] = 0\n",
    "\n",
    "        img_w = img_w.astype(np.uint8)\n",
    "        inverted = cv2.bitwise_not(img_w)\n",
    "        contours, _ = cv2.findContours(inverted, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contour_image = 255*np.ones((H,W))\n",
    "        cv2.drawContours(contour_image, contours, -1, 0, thickness=1)\n",
    "        img_list.append(contour_image)\n",
    "\n",
    "        # img_w = img_w.astype(np.uint8)\n",
    "        # inverted = cv2.bitwise_not(img_w)\n",
    "        # img_list.append(inverted)\n",
    "\n",
    "    return img_list, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3615b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_max_size(img, H_max=460, W_max=650):\n",
    "    \"\"\"Pads an image to specified maximum dimensions with white background (255 values).\n",
    "    \n",
    "    Centers the original image in the padded area. Useful for standardizing image sizes \n",
    "    in a dataset while preserving aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        img (numpy.ndarray): Input grayscale image as 2D array\n",
    "        H_max (int, optional): Maximum height for output image. Defaults to 460.\n",
    "        W_max (int, optional): Maximum width for output image. Defaults to 650.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Padded image with dimensions (H_max, W_max)\n",
    "    \"\"\"\n",
    "    padded_img = np.full((H_max, W_max), 255, dtype=np.uint8)\n",
    "\n",
    "    H, W = img.shape\n",
    "    y_start = (H_max - H) // 2\n",
    "    x_start = (W_max - W) // 2\n",
    "\n",
    "    padded_img[y_start:y_start+H, x_start:x_start+W] = img\n",
    "\n",
    "    return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ae755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_dict(folder_path):\n",
    "    \"\"\"Loads all PNG images from a directory into a dictionary with standardized dimensions.\n",
    "    \n",
    "    Processes images by:\n",
    "    1. Finding maximum height/width across all images\n",
    "    2. Loading each image\n",
    "    3. Binarizing using load_and_binarize()\n",
    "    4. Padding to max dimensions using pad_image_to_max_size()\n",
    "    5. Storing in dictionary with filenames as keys\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to directory containing PNG images\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary where:\n",
    "              - Key: filename (str)\n",
    "              - Value: processed image array (numpy.ndarray)\n",
    "              \n",
    "    Raises:\n",
    "        ValueError: If specified folder_path doesn't exist\n",
    "    \"\"\"\n",
    "    images_dict = {}\n",
    "\n",
    "    H_max = max(Image.open(os.path.join(folder_path, f)).size[1] for f in os.listdir(folder_path) if f.endswith(\".png\"))\n",
    "    W_max = max(Image.open(os.path.join(folder_path, f)).size[0] for f in os.listdir(folder_path) if f.endswith(\".png\"))\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise ValueError(f\"Folder {folder_path} does not exist\")\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                processed_image = load_and_binarize(file_path)\n",
    "                resized_image = pad_image_to_max_size(processed_image, H_max, W_max)\n",
    "                images_dict[filename] = resized_image\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process file {filename}: {e}\")\n",
    "    \n",
    "    return images_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blended_filename(img1_name, img2_name, weight, out_path):\n",
    "    \"\"\"Generates a standardized filename for blended images based on source images and blend weight.\n",
    "    \n",
    "    Extracts numerical indices from input filenames and creates a new filename in the format:\n",
    "    'idx_[img1_num]_[img2_num]_[weight_percent].png' in the specified output directory.\n",
    "\n",
    "    Args:\n",
    "        img1_name (str): Filename of first source image (e.g., 'frame1.png')\n",
    "        img2_name (str): Filename of second source image (e.g., 'frame2.png') \n",
    "        weight (float): Blend weight between 0 and 1 (e.g., 0.25 for 25% blend)\n",
    "        out_path (str): Directory path to save the new file\n",
    "        \n",
    "    Returns:\n",
    "        str: Full output path for blended image (e.g., '/output/idx_1_2_25.png')\n",
    "    \"\"\"\n",
    "    idx1 = int(''.join(filter(str.isdigit, img1_name)))\n",
    "    idx2 = int(''.join(filter(str.isdigit, img2_name)))\n",
    "    weight_str = f\"{round(weight * 100)}\"\n",
    "    filename = f\"idx_{idx1}_{idx2}_{weight_str}.png\"\n",
    "\n",
    "    return os.path.join(out_path, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc3552",
   "metadata": {},
   "source": [
    "Main function for generating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_save_dataset(ref_img_path, out_path='dataset', n_step=1):\n",
    "    \"\"\"Generates and saves a dataset of interpolated fluid flow images between all image pairs.\n",
    "    \n",
    "    Creates a complete dataset by:\n",
    "    1. Loading all reference images from input directory\n",
    "    2. Generating interpolated images between every unique pair\n",
    "    3. Saving results with standardized naming convention\n",
    "    4. Including self-interpolation for each reference image\n",
    "\n",
    "    Args:\n",
    "        ref_img_path (str): Path to directory containing reference PNG images\n",
    "        out_path (str, optional): Output directory for generated dataset. Defaults to 'dataset'.\n",
    "        n_step (int, optional): Number of interpolation steps between each image pair. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        None: Outputs files to disk instead of returning values\n",
    "\n",
    "    Prints:\n",
    "        Progress information including:\n",
    "        - Number of reference images\n",
    "        - Number of unique pairs\n",
    "        - Dataset size calculations\n",
    "        - Current interpolation pairs being processe\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img_dict = load_images_to_dict(ref_img_path)\n",
    "    keys = list(input_img_dict.keys())\n",
    "    n = len(keys)\n",
    "\n",
    "    print(f'Number of reference images: {n}\\nNumber of unique pairs: {comb(n,2)}\\nNumner of interpolation steps: {n_step}')\n",
    "    print(f'Size of dataset: {n_step*comb(n,2)} interpolated images + {n} reference images = {n_step*comb(n,2)+n} images')\n",
    "\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            print(f'Interpolation between images: {keys[i]}, {keys[j]}')\n",
    "            img_list, weights = interpolation(input_img_dict[keys[i]], input_img_dict[keys[j]], n_step=n_step)\n",
    "\n",
    "            for k, img in enumerate(img_list):\n",
    "                filename = generate_blended_filename(keys[i], keys[j], weights[k], out_path)\n",
    "                img = img.astype(np.uint8)\n",
    "                Image.fromarray(img).save(filename)\n",
    "\n",
    "        img_list, weights = interpolation(input_img_dict[keys[i]], input_img_dict[keys[i]], n_step=1)\n",
    "\n",
    "        for k, img in enumerate(img_list):\n",
    "            filename = generate_blended_filename(keys[i], keys[i], weights[k], out_path)\n",
    "            img = img.astype(np.uint8)\n",
    "            Image.fromarray(img).save(filename)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c7e88",
   "metadata": {},
   "source": [
    "Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_and_save_dataset('reference_images',out_path='dataset_thick',n_step=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5072c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_max = max(Image.open(os.path.join('dataset', f)).size[1] for f in os.listdir('dataset') if f.endswith(\".png\"))\n",
    "H_min = min(Image.open(os.path.join('dataset', f)).size[1] for f in os.listdir('dataset') if f.endswith(\".png\"))\n",
    "W_max = max(Image.open(os.path.join('dataset', f)).size[0] for f in os.listdir('dataset') if f.endswith(\".png\"))\n",
    "W_min = min(Image.open(os.path.join('dataset', f)).size[0] for f in os.listdir('dataset') if f.endswith(\".png\"))\n",
    "\n",
    "print(f'H_max = {H_max}, W_max = {W_max}')\n",
    "print(f'H_min = {H_min}, W_max = {W_min}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80366b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'dataset_thick'\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]\n",
    "\n",
    "random_image = random.choice(image_files)\n",
    "image_path = os.path.join(image_folder, random_image)\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(f'Random image: {random_image}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ed024",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images(source_folder, train_folder, test_folder, train_ratio=0.8):\n",
    "\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "    \n",
    "    images = [f for f in os.listdir(source_folder) if f.lower().endswith('.png')]\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    split_idx = floor(len(images) * train_ratio)\n",
    "    \n",
    "    for img in images[:split_idx]:\n",
    "        src = os.path.join(source_folder, img)\n",
    "        dst = os.path.join(train_folder, img)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "    for img in images[split_idx:]:\n",
    "        src = os.path.join(source_folder, img)\n",
    "        dst = os.path.join(test_folder, img)\n",
    "        shutil.copy2(src, dst)\n",
    "    \n",
    "    print(f\"All images: {len(images)}\")\n",
    "    print(f\"Train: {split_idx} ({train_ratio*100:.0f}%)\")\n",
    "    print(f\"Test: {len(images) - split_idx} ({(1-train_ratio)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c47a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"dataset\"\n",
    "train_folder = \"splitted_dataset/train\"\n",
    "test_folder = \"splitted_dataset/test\"\n",
    "\n",
    "split_images(source_folder, train_folder, test_folder, train_ratio=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
